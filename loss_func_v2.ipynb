{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcf8c3be-6178-491b-b0e1-a8075ee620bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(img, text):\n",
    "    \n",
    "    filler_img = 0\n",
    "    for i in img:\n",
    "        filler_img += i ** 2\n",
    "    filler_text = 0\n",
    "    for j in img:\n",
    "        filler_text += j ** 2\n",
    "\n",
    "    numer = np.dot(img,text)\n",
    "    denom = np.sqrt(filler_img) * np.sqrt(filler_text)\n",
    "    \n",
    "    return numer/denom\n",
    "\n",
    "#prob delete latr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b10ecc-2038-4050-9b21-937a389526ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mygrad as mg\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch \n",
    "test = [(48, 318556, 388611), (67, 116100, 412616), (126, 318556, 259951)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94fa670b-a233-4e7a-9ac1-ff0e71e82ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(triples_list, Wembed):\n",
    "    text, img_good, img_bad = zip(*triples_list)\n",
    "    text = np.array(text).reshape(-1, 1)\n",
    "    img_good = np.array(img_good).reshape(-1, 1)\n",
    "    img_bad = np.array(img_bad).reshape(-1, 1)\n",
    "    #getting tuples n turning them into the correct arrays\n",
    "\n",
    "    img_good_embed = np.dot(img_good, Wembed.detach().numpy())\n",
    "    img_bad_embed = np.dot(img_bad, Wembed.detach().numpy())\n",
    "\n",
    "    sim_to_good = cosine_similarity(text, img_good_embed)\n",
    "    sim_to_bad = cosine_similarity(text, img_bad_embed)\n",
    "    #sim_to_good = sim(text, img_good)\n",
    "    #sim_to_bad = sim(text, img_bad)\n",
    "    #my other ver of cosine sim\n",
    "    \n",
    "    y = np.ones(len(text)) #1 or -1, 1 makes it so that its x1 - x2 (vice versa with -1).\n",
    "    \n",
    "    return mg.nnet.losses.margin_ranking_loss(sim_to_good, sim_to_bad, y, margin = 0.25) #what notebook said"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3d7fed8-9f37-497e-828d-32c6ae4866af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wembed = mg.nnet.initializers.glorot_normal(512,200)\n",
    "Wembed = torch.nn.Parameter(torch.randn(512, 200), requires_grad=True)\n",
    "optimizer = torch.optim.SGD([Wembed], lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13ae7546-12e8-4758-8ce7-a8b64bd7a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(triples_list, Wembed, optimizer, num_epochs, batch_size=32):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, len(triples_list), batch_size):\n",
    "            batch = triples_list[i:i+batch_size]\n",
    "            loss = loss_func(batch, Wembed)  \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7e52b27-071e-4dae-84fa-004ef309c0af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,1) and (512,200) not aligned: 1 (dim 1) != 512 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWembed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(triples_list, Wembed, optimizer, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(triples_list), batch_size):\n\u001b[1;32m      4\u001b[0m     batch \u001b[38;5;241m=\u001b[39m triples_list[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m----> 5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWembed\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m, in \u001b[0;36mloss_func\u001b[0;34m(triples_list, Wembed)\u001b[0m\n\u001b[1;32m      5\u001b[0m img_bad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img_bad)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#getting tuples n turning them into the correct arrays\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m img_good_embed \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_good\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWembed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m img_bad_embed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(img_bad, Wembed\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     11\u001b[0m sim_to_good \u001b[38;5;241m=\u001b[39m cosine_similarity(text, img_good_embed)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,1) and (512,200) not aligned: 1 (dim 1) != 512 (dim 0)"
     ]
    }
   ],
   "source": [
    "train(test, Wembed, optimizer, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100e55a-d06d-4dae-8a18-edab5ff0c0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
